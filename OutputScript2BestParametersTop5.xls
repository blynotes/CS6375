0.9305	{'epsilon': 1e-08, 'learning_rate': 0.0015, 'layers': [{'keep_prob': 0.49999999999999994, 'layerSize': 1176, 'dropoutFlag': True, 'regLambda': 0, 'nodeType': 'ReLU'}, {'keep_prob': 0.7, 'layerSize': 588, 'dropoutFlag': True, 'regLambda': 0, 'nodeType': 'ReLU'}, {'keep_prob': 0.6, 'layerSize': 1323, 'dropoutFlag': True, 'regLambda': 0.00080000000000000004, 'nodeType': 'ReLU'}, {'keep_prob': 1, 'layerSize': 10, 'dropoutFlag': False, 'regLambda': 0.005, 'nodeType': 'Linear'}], 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 100}	35.30445737374248	Best Parameters on run 1 for lambdaVal3
0.9287	{'epsilon': 1e-08, 'beta2': 0.999, 'batch_size': 100, 'learning_rate': 0.001, 'layers': [{'keep_prob': 0.55, 'nodeType': 'ReLU', 'regLambda': 0, 'layerSize': 1176, 'dropoutFlag': False}, {'keep_prob': 0.7, 'nodeType': 'ReLU', 'regLambda': 0, 'layerSize': 980, 'dropoutFlag': True}, {'keep_prob': 0.6, 'nodeType': 'ReLU', 'regLambda': 0, 'layerSize': 1323, 'dropoutFlag': True}, {'keep_prob': 1, 'nodeType': 'Linear', 'regLambda': 0.005, 'layerSize': 10, 'dropoutFlag': False}], 'beta1': 0.9}	40.49590509376412	Best Parameters on run 1 for layer3
0.9281	{'epsilon': 1e-08, 'learning_rate': 0.0015, 'layers': [{'keep_prob': 0.49999999999999994, 'layerSize': 1176, 'dropoutFlag': True, 'regLambda': 0, 'nodeType': 'ReLU'}, {'keep_prob': 0.7, 'layerSize': 588, 'dropoutFlag': True, 'regLambda': 0, 'nodeType': 'ReLU'}, {'keep_prob': 0.6, 'layerSize': 1323, 'dropoutFlag': True, 'regLambda': 0, 'nodeType': 'ReLU'}, {'keep_prob': 1, 'layerSize': 10, 'dropoutFlag': False, 'regLambda': 0.005, 'nodeType': 'Linear'}], 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 100}	35.31332764181661	Best Parameters on run 1 for learnRate
0.928	{'epsilon': 1e-08, 'learning_rate': 0.001, 'layers': [{'keep_prob': 0.49999999999999994, 'layerSize': 1176, 'dropoutFlag': True, 'regLambda': 0, 'nodeType': 'ReLU'}, {'keep_prob': 0.7, 'layerSize': 588, 'dropoutFlag': True, 'regLambda': 0, 'nodeType': 'ReLU'}, {'keep_prob': 0.6, 'layerSize': 1323, 'dropoutFlag': True, 'regLambda': 0, 'nodeType': 'ReLU'}, {'keep_prob': 1, 'layerSize': 10, 'dropoutFlag': False, 'regLambda': 0.005, 'nodeType': 'Linear'}], 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 100}	35.24834550741343	Best Parameters on run 1 for layer2
0.9278	{'beta2': 0.999, 'batch_size': 100, 'beta1': 0.9, 'layers': [{'regLambda': 0.00050000000000000001, 'dropoutFlag': True, 'keep_prob': 0.55, 'nodeType': 'ReLU', 'layerSize': 784}, {'regLambda': 0.00050000000000000001, 'dropoutFlag': True, 'keep_prob': 0.7, 'nodeType': 'ReLU', 'layerSize': 280}, {'regLambda': 0.00050000000000000001, 'dropoutFlag': False, 'keep_prob': 1, 'nodeType': 'Linear', 'layerSize': 10}], 'epsilon': 1e-08, 'learning_rate': 0.001}	28.867782307750986	Best Parameters on run 1 for layer2
